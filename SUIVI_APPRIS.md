# SUIVI APPRIS - Aujourduy Production

## Base de connaissances - Le√ßons et solutions

### üöÄ Best Practice : Git-based Deployment avec Kamal (Session 27)

**Architecture actuelle (√† migrer) :**
- 2 repos Git s√©par√©s : `Aujourduy` (dev) et `Aujourduy-prod` (prod)
- D√©ploiement : rsync manuel + copie DB compl√®te
- Risques : Perte donn√©es prod, pas de rollback, pas de tra√ßabilit√©

**Architecture recommand√©e (Rails 8 best practice) :**
```
Un seul repo Git avec branches :
- main ‚Üí Production (3graces.community)
- develop ‚Üí Dev (dev.aujourduy.fr)
- feature/* ‚Üí Features en cours

D√©ploiement : git push main ‚Üí Kamal ‚Üí Zero-downtime deployment
Donn√©es : Migrations incr√©mentales (pas de copie DB)
```

**Workflow Kamal :**
1. D√©velopper en `develop`, commit, push
2. Merger vers `main` (ou cherry-pick commits)
3. Push ‚Üí Kamal d√©tecte et d√©ploie automatiquement
4. Kamal : build ‚Üí push image ‚Üí lance containers ‚Üí migrate DB ‚Üí switch trafic ‚Üí zero downtime
5. Si probl√®me : `kamal rollback` (retour version pr√©c√©dente en 1 commande)

**B√©n√©fices vs approche actuelle :**
| Crit√®re | Actuel (rsync) | Kamal |
|---------|----------------|-------|
| Perte donn√©es prod | ‚ö†Ô∏è Risque √©lev√© (copie DB) | ‚úÖ Aucune (migrations) |
| Rollback | ‚ùå Manuel et complexe | ‚úÖ 1 commande |
| Downtime | ‚ö†Ô∏è Red√©marrage requis | ‚úÖ Zero downtime |
| Tra√ßabilit√© | ‚ö†Ô∏è Manuelle (SUIVI*.md) | ‚úÖ Git historique |
| CI/CD | ‚ùå Aucun | ‚úÖ Int√©grable facilement |

**Documentation compl√®te :**
- Plan d√©taill√© : ~/Aujourduy/SUIVI_ENCOURS.md (4 phases de migration)
- Justification : ~/Aujourduy/SUIVI_APPRIS.md (comparaison d√©taill√©e)

**Statut :** Planifi√©, √† impl√©menter lors d'une session d√©di√©e

---

### üîÑ Copie Base de Donn√©es DEV ‚Üí PROD (Session 26)

**Outil cr√©√© :**
- Script : `/home/dang/Aujourduy-prod/db-dev-to-prod.sh`
- Alias : `db-dev-prod`
- Documentation : `README_DB_COPY.md`

**Fonctionnement :**
1. Dump de DEV avec `pg_dump --clean --if-exists`
2. Restauration dans PROD via `psql`
3. Stats avant/apr√®s pour validation
4. Confirmation interactive (s√©curit√©)
5. Nettoyage automatique

**Important :**
- Les credentials PROD sont extraites dynamiquement du `.env` PROD
- Les credentials DEV sont en dur (base stable)
- Dump horodat√© pour tra√ßabilit√©

---

### üåê Configuration Domaine www avec Cloudflare (Session 26)

**Probl√®me :**
- www.3graces.community pointait vers Google Sites au lieu de Rails

**Cause :**
- Ancien CNAME dans Cloudflare DNS : `www ‚Üí ghs.googlehosted.com`

**Solution :**
1. Supprimer le CNAME existant dans Cloudflare DNS (PAS IONOS)
2. Ajouter www.3graces.community dans Cloudflare Tunnel public hostnames
3. Cloudflare cr√©e automatiquement le bon CNAME vers le tunnel

**Architecture DNS :**
```
IONOS (registrar) ‚Üí Nameservers Cloudflare
                  ‚Üì
Cloudflare DNS ‚Üí apex (3graces.community) ‚Üí Tunnel
              ‚Üí www (www.3graces.community) ‚Üí Tunnel
              ‚Üí n8n-prod ‚Üí Tunnel
```

**Le√ßon :**
- Toujours v√©rifier o√π sont g√©r√©s les records (registrar vs CDN/DNS)
- IONOS est juste le registrar, Cloudflare g√®re le DNS
- Cloudflare Tunnel g√®re automatiquement les CNAME apr√®s ajout du hostname

---

### ‚ö° Performance Rails DEV vs PROD (Session 26)

**Benchmarks mesur√©s :**
- Homepage : 33% plus rapide en PROD
- Events : 30% plus rapide
- Teachers : 35% plus rapide

**Pourquoi seulement 30% ?**
- DEV est d√©j√† tr√®s optimis√© (PostgreSQL, PgBouncer, Docker)
- Les gains typiques (50-70%) s'appliquent aux setups DEV mal configur√©s (SQLite, async jobs, etc.)
- Avec m√™me architecture DEV/PROD, le gain vient principalement de :
  - Moins de logging (84% moins en PROD)
  - Mode production Rails (pas de reload, optimisations)
  - Cloudflare CDN pour assets statiques

**Diff√©rences Logging :**
- DEV : log_level = :debug (0) ‚Üí ~25 lignes/requ√™te
- PROD : log_level = :info (1) ‚Üí 4 lignes/requ√™te
- Impact : Moins d'I/O disque, logs plus lisibles

---

### üê≥ Docker Compose Production (Sessions pr√©c√©dentes)

**Services critiques :**
- `postgres-prod` : PostgreSQL 16 avec SCRAM-SHA-256
- `pgbouncer-prod` : Connection pooling (transaction mode, port 6432)
- `rails-prod` : App Rails sur port 3002
- `solid-queue-prod` : Background jobs Rails 8
- `n8n-prod` : Automation (port 5679)
- `playwright` : Tests E2E

**Configuration PgBouncer :**
- Fichier : `pgbouncer/pgbouncer.ini`
- Mode : transaction
- Auth : SCRAM-SHA-256 via `userlist.txt`
- Port expos√© : 6433 (Tailscale), 6432 (interne Docker)

---

### üîê OAuth Google Production (Sessions pr√©c√©dentes)

**Configuration :**
- `rails/config/initializers/omniauth.rb` : Redirect URI dynamique selon ENV
- Variables : `RAILS_HOST`, `RAILS_FORCE_SSL`
- Callback : https://3graces.community/users/auth/google_oauth2/callback

**Le√ßon :**
- TOUJOURS tester OAuth en HTTPS avant de d√©ployer
- Les redirect URIs doivent √™tre configur√©s dans Google Cloud Console
- Rails d√©tecte automatiquement HTTPS via Cloudflare headers

---

### üîÑ Solid Queue Production (Sessions pr√©c√©dentes)

**Configuration :**
- `rails/config/recurring.yml` : Schedule des jobs r√©currents
- Format cron accept√© pour les schedules complexes
- Exemple : `"0 3 1 1 *"` pour "1er janvier √† 3h"

**Probl√®me rencontr√© :**
- Schedule au format texte "yearly" causait des erreurs
- Solution : Utiliser format cron standard

---

### üîë n8n Production (Sessions pr√©c√©dentes)

**Configuration critique :**
- `N8N_ENCRYPTION_KEY` : DOIT √™tre identique entre DEV et PROD pour importer workflows
- `N8N_PORT` : 5678 en PROD (coh√©rence avec nom de domaine)
- Cloudflare Tunnel : https://n8n-prod.3graces.community

**Le√ßon :**
- Si encryption key diff√©rente, les credentials ne sont pas importables
- Toujours v√©rifier le port dans `.env` ET `docker-compose.yml`
